import "dart:convert";
import "dart:io";

import "package:flutter_test/flutter_test.dart";
import "package:yata/core/utils/provider_logger.dart";

import "helpers/performance_baseline.dart";
import "helpers/performance_test_helper.dart";

/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
/// 
/// CI/CDç’°å¢ƒã§ã®è‡ªå‹•å®Ÿè¡Œã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€
/// å›å¸°æ¤œå‡ºã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹
class PerformanceTestRunner {

  PerformanceTestRunner({
    PerformanceTestConfig? config,
  }) : config = config ?? const PerformanceTestConfig();
  static const String _component = "PerformanceTestRunner";

  /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œè¨­å®š
  final PerformanceTestConfig config;

  /// å®Ÿè¡Œçµæœã®æ ¼ç´
  final List<PerformanceTestResult> _results = <PerformanceTestResult>[];
  final List<RegressionDetectionResult> _regressions = <RegressionDetectionResult>[];

  // =================================================================
  // ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¡ã‚½ãƒƒãƒ‰
  // =================================================================

  /// å…¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
  /// 
  /// [testSuites] å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆåã®ãƒªã‚¹ãƒˆ
  /// æˆ»ã‚Šå€¤: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼
  Future<PerformanceTestSummary> runAllTests({
    List<String>? testSuites,
  }) async {
    ProviderLogger.info(_component, "ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹");
    
    final DateTime startTime = DateTime.now();
    
    try {
      // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä½¿ç”¨
      final List<String> suitesToRun = testSuites ?? <String>[
        "provider_performance",
        "ui_performance",
        "memory_leak",
        "integration_performance",
      ];

      // å„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’å®Ÿè¡Œ
      for (final String suite in suitesToRun) {
        ProviderLogger.info(_component, "ğŸ“‹ ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ: $suite");
        await _runTestSuite(suite);
      }

      // çµæœåˆ†æã¨å›å¸°æ¤œå‡º
      await _analyzeResults();

      // ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
      final PerformanceTestSummary summary = await _generateSummary(startTime);

      // çµæœå‡ºåŠ›
      await _outputResults(summary);

      ProviderLogger.info(_component, "âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†");
      return summary;

    } catch (e, stackTrace) {
      ProviderLogger.error(_component, "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ", e, stackTrace);
      
      return PerformanceTestSummary(
        totalTests: 0,
        passedTests: 0,
        failedTests: 1,
        regressionCount: 0,
        executionTimeMs: DateTime.now().difference(startTime).inMilliseconds,
        results: <PerformanceTestResult>[],
        regressions: <RegressionDetectionResult>[],
        success: false,
        errorMessage: e.toString(),
      );
    }
  }

  /// å€‹åˆ¥ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
  Future<void> _runTestSuite(String suiteName) async {
    switch (suiteName) {
      case "provider_performance":
        await _runProviderPerformanceTests();
        break;
      case "ui_performance":
        await _runUIPerformanceTests();
        break;
      case "memory_leak":
        await _runMemoryLeakTests();
        break;
      case "integration_performance":
        await _runIntegrationPerformanceTests();
        break;
      default:
        ProviderLogger.warning(_component, "æœªçŸ¥ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ: $suiteName");
    }
  }

  // =================================================================
  // å€‹åˆ¥ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè£…
  // =================================================================

  /// ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  Future<void> _runProviderPerformanceTests() async {
    ProviderLogger.info(_component, "ğŸ”§ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ");

    // èªè¨¼ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ
    final PerformanceTestResult authResult = await PerformanceTestHelper.measurePerformance(
      "auth_provider_benchmark",
      () async {
        // èªè¨¼ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        final Future<void> delay1 = Future.delayed(const Duration(milliseconds: 50)); // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        await delay1;
      },
      expectedMaxDuration: PerformanceTestHelper.providerInitWarningThreshold,
      memoryThreshold: 1.0,
    );
    _results.add(authResult);

    // åœ¨åº«ç®¡ç†ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ
    final PerformanceTestResult inventoryResult = await PerformanceTestHelper.measurePerformance(
      "inventory_provider_benchmark",
      () async {
        final Future<void> delay2 = Future.delayed(const Duration(milliseconds: 75)); // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        await delay2;
      },
      expectedMaxDuration: PerformanceTestHelper.providerInitWarningThreshold,
      memoryThreshold: 2.0,
    );
    _results.add(inventoryResult);

    // æ³¨æ–‡ç®¡ç†ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ
    final PerformanceTestResult orderResult = await PerformanceTestHelper.measurePerformance(
      "order_provider_benchmark",
      () async {
        final Future<void> delay3 = Future.delayed(const Duration(milliseconds: 60)); // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        await delay3;
      },
      expectedMaxDuration: PerformanceTestHelper.providerInitWarningThreshold,
      memoryThreshold: 1.5,
    );
    _results.add(orderResult);

    ProviderLogger.info(_component, "âœ… ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†");
  }

  /// UIæç”»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  Future<void> _runUIPerformanceTests() async {
    ProviderLogger.info(_component, "ğŸ¨ UIæç”»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ");

    // UIæç”»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    final PerformanceTestResult uiResult = await PerformanceTestHelper.measurePerformance(
      "ui_rendering_benchmark",
      () async {
        // UIæç”»å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        for (int i = 0; i < 10; i++) {
          final Future<void> delay4 = Future.delayed(const Duration(milliseconds: 16)); // 60FPSæƒ³å®š
          await delay4;
        }
      },
      expectedMaxDuration: PerformanceTestHelper.uiRenderCriticalThreshold * 10,
      memoryThreshold: 0.5,
    );
    _results.add(uiResult);

    ProviderLogger.info(_component, "âœ… UIæç”»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†");
  }

  /// ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  Future<void> _runMemoryLeakTests() async {
    ProviderLogger.info(_component, "ğŸ’§ ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ");

    // ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
    final MemoryLeakTestResult memoryResult = await PerformanceTestHelper.testMemoryLeak(
      "general_memory_leak_test",
      () async {
        // ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã™ã‚‹å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        final List<String> memoryConsumer = List.generate(1000, (int i) => "ãƒ‡ãƒ¼ã‚¿$i");
        final Future<void> delay5 = Future.delayed(const Duration(milliseconds: 10));
        await delay5;
        memoryConsumer.clear(); // æ˜ç¤ºçš„ã«ã‚¯ãƒªã‚¢
      },
      () async {
        // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
        final Future<void> delay6 = Future.delayed(const Duration(milliseconds: 5));
        await delay6;
      },
      maxMemoryLeakMB: 1.0,
    );

    // ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯çµæœã‚’ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœã¨ã—ã¦è¨˜éŒ²
    _results.add(PerformanceTestResult(
      testName: memoryResult.testName,
      executionTimeMs: 0, // ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã§ã¯å®Ÿè¡Œæ™‚é–“ã¯é–¢ä¿‚ãªã—
      memoryUsageMB: memoryResult.memoryLeakMB,
      initialMemoryMB: memoryResult.initialMemoryMB,
      finalMemoryMB: memoryResult.finalMemoryMB,
      success: memoryResult.passed,
      timestamp: memoryResult.timestamp,
    ));

    ProviderLogger.info(_component, "âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†");
  }

  /// çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
  Future<void> _runIntegrationPerformanceTests() async {
    ProviderLogger.info(_component, "ğŸ”— çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ");

    // ã‚¢ãƒ—ãƒªå…¨ä½“ã®åˆæœŸåŒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    final PerformanceTestResult integrationResult = await PerformanceTestHelper.measurePerformance(
      "app_initialization_benchmark",
      () async {
        // ã‚¢ãƒ—ãƒªåˆæœŸåŒ–å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        final Future<void> delay7 = Future.delayed(const Duration(milliseconds: 200));
        await delay7;
      },
      expectedMaxDuration: 1000, // 1ç§’ä»¥å†…
      memoryThreshold: 10.0, // 10MBä»¥å†…
    );
    _results.add(integrationResult);

    ProviderLogger.info(_component, "âœ… çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†");
  }

  // =================================================================
  // çµæœåˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  // =================================================================

  /// ãƒ†ã‚¹ãƒˆçµæœã®åˆ†æã¨å›å¸°æ¤œå‡º
  Future<void> _analyzeResults() async {
    ProviderLogger.info(_component, "ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœåˆ†æé–‹å§‹");

    for (final PerformanceTestResult result in _results) {
      // å›å¸°æ¤œå‡º
      final RegressionDetectionResult regression = await PerformanceBaseline.detectRegression(
        result.testName,
        result,
        regressionThreshold: config.regressionThresholdPercent,
      );

      if (regression.hasRegression) {
        _regressions.add(regression);
      }

      // ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ›´æ–°ï¼ˆæˆåŠŸã—ãŸãƒ†ã‚¹ãƒˆã®ã¿ï¼‰
      if (result.success && !regression.hasRegression && config.updateBaseline) {
        await PerformanceBaseline.updateBaseline(result.testName, result);
      }
    }

    ProviderLogger.info(_component, "ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœåˆ†æå®Œäº†");
  }

  /// ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ
  Future<PerformanceTestSummary> _generateSummary(DateTime startTime) async {
    final int totalTests = _results.length;
    final int passedTests = _results.where((PerformanceTestResult r) => r.success).length;
    final int failedTests = totalTests - passedTests;
    final int regressionCount = _regressions.length;
    final int executionTimeMs = DateTime.now().difference(startTime).inMilliseconds;

    return PerformanceTestSummary(
      totalTests: totalTests,
      passedTests: passedTests,
      failedTests: failedTests,
      regressionCount: regressionCount,
      executionTimeMs: executionTimeMs,
      results: List.from(_results),
      regressions: List.from(_regressions),
      success: failedTests == 0 && regressionCount == 0,
    );
  }

  /// ãƒ†ã‚¹ãƒˆçµæœã®å‡ºåŠ›
  Future<void> _outputResults(PerformanceTestSummary summary) async {
    // JSONå½¢å¼ã§çµæœä¿å­˜
    await PerformanceBaseline.saveTestResults(_results);

    // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    _printSummaryToConsole(summary);

    // CI/CDç”¨ã®JUnitå½¢å¼ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    if (config.generateJUnitReport) {
      await _generateJUnitReport(summary);
    }

    // è©³ç´°JSON ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    if (config.generateDetailedReport) {
      await _generateDetailedJsonReport(summary);
    }
  }

  /// ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¸ã®ã‚µãƒãƒªãƒ¼å‡ºåŠ›
  void _printSummaryToConsole(PerformanceTestSummary summary) {
    print('\n${'=' * 60}');
    print("ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼");
    print("=" * 60);
    print("ç·ãƒ†ã‚¹ãƒˆæ•°: ${summary.totalTests}");
    print("æˆåŠŸ: ${summary.passedTests}");
    print("å¤±æ•—: ${summary.failedTests}");
    print("å›å¸°æ¤œå‡º: ${summary.regressionCount}");
    print("å®Ÿè¡Œæ™‚é–“: ${summary.executionTimeMs}ms");
    print('ãƒ†ã‚¹ãƒˆçµæœ: ${summary.success ? "âœ… æˆåŠŸ" : "âŒ å¤±æ•—"}');
    
    if (summary.regressionCount > 0) {
      print("\nğŸš¨ æ¤œå‡ºã•ã‚ŒãŸå›å¸°:");
      for (final RegressionDetectionResult regression in summary.regressions) {
        print("  - ${regression.testName}: ${regression.reason}");
        print("    å®Ÿè¡Œæ™‚é–“: ${regression.executionTimeRegressionPercent.toStringAsFixed(1)}%");
        print("    ãƒ¡ãƒ¢ãƒª: ${regression.memoryRegressionPercent.toStringAsFixed(1)}%");
      }
    }
    
    print("=" * 60);
  }

  /// JUnitå½¢å¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  Future<void> _generateJUnitReport(PerformanceTestSummary summary) async {
    final StringBuffer xml = StringBuffer()
      ..writeln('<?xml version="1.0" encoding="UTF-8"?>')
      ..writeln('<testsuite name="PerformanceTests" '
          'tests="${summary.totalTests}" '
          'failures="${summary.failedTests}" '
          'time="${(summary.executionTimeMs / 1000).toStringAsFixed(3)}">');

    for (final PerformanceTestResult result in summary.results) {
      xml.writeln('  <testcase name="${result.testName}" '
          'time="${(result.executionTimeMs / 1000).toStringAsFixed(3)}">');
      
      if (!result.success) {
        xml.writeln('    <failure message="${result.exception?.toString() ?? 'Unknown failure'}"/>');
      }
      
      xml.writeln("  </testcase>");
    }

    xml.writeln("</testsuite>");

    final File junitFile = File("performance_test_results.xml");
    await junitFile.writeAsString(xml.toString());
    
    ProviderLogger.info(_component, "JUnitãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: ${junitFile.path}");
  }

  /// è©³ç´°JSONãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  Future<void> _generateDetailedJsonReport(PerformanceTestSummary summary) async {
    final Map<String, dynamic> report = summary.toJson();
    
    final File jsonFile = File("performance_detailed_report.json");
    await jsonFile.writeAsString(
      const JsonEncoder.withIndent("  ").convert(report),
    );
    
    ProviderLogger.info(_component, "è©³ç´°JSONãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: ${jsonFile.path}");
  }
}

// =================================================================
// è¨­å®šãƒ»ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
// =================================================================

/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œè¨­å®š
class PerformanceTestConfig {
  const PerformanceTestConfig({
    this.regressionThresholdPercent = 20.0,
    this.updateBaseline = true,
    this.generateJUnitReport = true,
    this.generateDetailedReport = true,
  });

  /// å›å¸°æ¤œå‡ºã®é–¾å€¤ï¼ˆï¼…ï¼‰
  final double regressionThresholdPercent;
  
  /// ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è‡ªå‹•æ›´æ–°ãƒ•ãƒ©ã‚°
  final bool updateBaseline;
  
  /// JUnitå½¢å¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ•ãƒ©ã‚°
  final bool generateJUnitReport;
  
  /// è©³ç´°JSONãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ•ãƒ©ã‚°
  final bool generateDetailedReport;
}

/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼
class PerformanceTestSummary {
  const PerformanceTestSummary({
    required this.totalTests,
    required this.passedTests,
    required this.failedTests,
    required this.regressionCount,
    required this.executionTimeMs,
    required this.results,
    required this.regressions,
    required this.success,
    this.errorMessage,
  });

  final int totalTests;
  final int passedTests;
  final int failedTests;
  final int regressionCount;
  final int executionTimeMs;
  final List<PerformanceTestResult> results;
  final List<RegressionDetectionResult> regressions;
  final bool success;
  final String? errorMessage;

  /// JSONå½¢å¼ã§ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º
  Map<String, dynamic> toJson() => <String, dynamic>{
        "totalTests": totalTests,
        "passedTests": passedTests,
        "failedTests": failedTests,
        "regressionCount": regressionCount,
        "executionTimeMs": executionTimeMs,
        "success": success,
        "errorMessage": errorMessage,
        "results": results.map((PerformanceTestResult r) => r.toJson()).toList(),
        "regressions": regressions.map((RegressionDetectionResult r) => r.toJson()).toList(),
        "timestamp": DateTime.now().toIso8601String(),
      };
}

// =================================================================
// CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
// =================================================================

/// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œç”¨ã®ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰
Future<void> main(List<String> args) async {
  // ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
  final PerformanceTestConfig config = _parseArgs(args);
  
  // ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼å®Ÿè¡Œ
  final PerformanceTestRunner runner = PerformanceTestRunner(config: config);
  final PerformanceTestSummary summary = await runner.runAllTests();
  
  // çµ‚äº†ã‚³ãƒ¼ãƒ‰è¨­å®šï¼ˆCI/CDç”¨ï¼‰
  exit(summary.success ? 0 : 1);
}

/// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è§£æ
PerformanceTestConfig _parseArgs(List<String> args) {
  bool updateBaseline = true;
  bool generateJUnitReport = true;
  bool generateDetailedReport = true;
  double regressionThreshold = 20.0;

  for (int i = 0; i < args.length; i++) {
    switch (args[i]) {
      case "--no-update-baseline":
        updateBaseline = false;
        break;
      case "--no-junit":
        generateJUnitReport = false;
        break;
      case "--no-detailed-report":
        generateDetailedReport = false;
        break;
      case "--regression-threshold":
        if (i + 1 < args.length) {
          regressionThreshold = double.tryParse(args[i + 1]) ?? 20.0;
          i++; // æ¬¡ã®å¼•æ•°ã‚’ã‚¹ã‚­ãƒƒãƒ—
        }
        break;
    }
  }

  return PerformanceTestConfig(
    updateBaseline: updateBaseline,
    generateJUnitReport: generateJUnitReport,
    generateDetailedReport: generateDetailedReport,
    regressionThresholdPercent: regressionThreshold,
  );
}